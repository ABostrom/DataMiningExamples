{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitdeeprlcondabc608767d7cf433ca3c76fb9b75440c0",
   "display_name": "Python 3.7.7 64-bit ('DeepRL': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Heart Disease UCI\n",
    "\n",
    "subset of the 74 attributes in the original: https://archive.ics.uci.edu/ml/datasets/heart+disease\n",
    "\n",
    "Attribute Information:\n",
    "- age\n",
    "- sex\n",
    "- chest pain type (4 values)\n",
    "- resting blood pressure\n",
    "- serum cholestoral in mg/dl\n",
    "- fasting blood sugar > 120 mg/dl\n",
    "- resting electrocardiographic results (values 0,1,2)\n",
    "- maximum heart rate achieved\n",
    "- exercise induced angina\n",
    "- oldpeak = ST depression induced by exercise relative to rest\n",
    "- the slope of the peak exercise ST segment\n",
    "- number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#designate the path where you saved your OEC data\n",
    "heart_data_path = \"../../Datasets/heart.csv\""
   ]
  },
  {
   "source": [
    "## Explore the Data\n",
    "Look at the distributions or histograms of individual attributes.\n",
    "\n",
    "Examine the mean and standard deviation for each attribute.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Build and train a standard pipeline with atleast one scaling/transformation stage and a classification stage."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Plot the precision and recall for the pipeline you have built"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "source": [
    "Output the accuracy, balanced accuracy and f1 score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "source": [
    "Build a parameter grid of classifiers and transformers to use for a cross-validated search\n",
    "\n",
    "This could include passthrough, multiple seqeuences of transformer , a single transformer. \n",
    "But msut always end up in a classifier.\n",
    "\n",
    "Consider the classifeirs, `Logistic Regression` `Support Vector Machines` and `Decision Trees`\n",
    "\n",
    "Consider the possible transformers: `MinMaxScaler`, `Normalizer`, `PowerTransformer`, `QuantileTransformer`, `StandardScaler`\n",
    "\n",
    "\n",
    "Consider using `ParameterGrid` to generate sets of parameters for your classifiers\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "\n",
    "\n",
    "Through Cross Validation. Find the best pipeline seqeuence to transform the data into a more suitable space (or no transformation),\n",
    "and perform classification on the target to maximise the Accuracy.\n",
    "\n",
    "\n",
    "Consider using `GridSearchCV` \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "\n",
    "\n",
    "## Plot the results of the tuned classifier\n",
    "\n",
    "Firstly show the precision and recall of the GridSearchCV.\n",
    "\n",
    "Secondly construct the Area under the reciving operator characteristic\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Rather than using a exhaustive grid search of all your parameters.\n",
    "Which depending on dataset size could take a long time.\n",
    "\n",
    "We can use different types of hyper parameter optimisation, one such example is `RandomizedSearchCV`\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\n",
    "\n",
    "Read the documenation and try and implement our pipeline using RandomizedSearchCV instead of GridSearchCV\n",
    "\n",
    "Plot the ROC and Precision/Recall curves as before. \n",
    "\n",
    "Examine the parameters selected. \n",
    "What changes?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}