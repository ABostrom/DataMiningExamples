{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0a6b797a4091570d69f8a8160f81f5dba34294d1e3a310d498be04ef5196ed8f6",
   "display_name": "Python 3.7.9 64-bit ('DeepRL': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>shrimp</td>\n      <td>almonds</td>\n      <td>avocado</td>\n      <td>vegetables mix</td>\n      <td>green grapes</td>\n      <td>whole weat flour</td>\n      <td>yams</td>\n      <td>cottage cheese</td>\n      <td>energy drink</td>\n      <td>tomato juice</td>\n      <td>low fat yogurt</td>\n      <td>green tea</td>\n      <td>honey</td>\n      <td>salad</td>\n      <td>mineral water</td>\n      <td>salmon</td>\n      <td>antioxydant juice</td>\n      <td>frozen smoothie</td>\n      <td>spinach</td>\n      <td>olive oil</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>burgers</td>\n      <td>meatballs</td>\n      <td>eggs</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>chutney</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>turkey</td>\n      <td>avocado</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mineral water</td>\n      <td>milk</td>\n      <td>energy bar</td>\n      <td>whole wheat rice</td>\n      <td>green tea</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "# load some relational database\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# this is a dataset of items customers bought over a week period\n",
    "store_data = pd.read_csv(\"../../Datasets/store_data.csv\", header=None)\n",
    "store_data.head()\n"
   ]
  },
  {
   "source": [
    "Here i perform this manually  or in the next cell you'll see you can use the transaction encoder from mlxtend"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to encode our shopping lists into a one hot encoded dataset. This means we need to get the data into a list of lists format, and find the unique fields.\n",
    "\n",
    "#convert the data frame to a list of list\n",
    "data = store_data.values.tolist() \n",
    "# remove straggling nans in the lists.\n",
    "data = [[i for i in j if i == i] for j in data]\n",
    "from itertools import chain\n",
    "# get the unique columns from all the strings\n",
    "unique = np.unique(list(chain(*data)))\n",
    "# get a true/false matrix of present or not present when compared against the row.\n",
    "inds = [np.in1d(unique, row).tolist() for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    asparagus  almonds  antioxydant juice  asparagus  avocado  babies food  \\\n",
       "0       False     True               True      False     True        False   \n",
       "1       False    False              False      False    False        False   \n",
       "2       False    False              False      False    False        False   \n",
       "3       False    False              False      False     True        False   \n",
       "4       False    False              False      False    False        False   \n",
       "\n",
       "   bacon  barbecue sauce  black tea  blueberries  ...  turkey  vegetables mix  \\\n",
       "0  False           False      False        False  ...   False            True   \n",
       "1  False           False      False        False  ...   False           False   \n",
       "2  False           False      False        False  ...   False           False   \n",
       "3  False           False      False        False  ...    True           False   \n",
       "4  False           False      False        False  ...   False           False   \n",
       "\n",
       "   water spray  white wine  whole weat flour  whole wheat pasta  \\\n",
       "0        False       False              True              False   \n",
       "1        False       False             False              False   \n",
       "2        False       False             False              False   \n",
       "3        False       False             False              False   \n",
       "4        False       False             False              False   \n",
       "\n",
       "   whole wheat rice   yams  yogurt cake  zucchini  \n",
       "0             False   True        False     False  \n",
       "1             False  False        False     False  \n",
       "2             False  False        False     False  \n",
       "3             False  False        False     False  \n",
       "4              True  False        False     False  \n",
       "\n",
       "[5 rows x 120 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asparagus</th>\n      <th>almonds</th>\n      <th>antioxydant juice</th>\n      <th>asparagus</th>\n      <th>avocado</th>\n      <th>babies food</th>\n      <th>bacon</th>\n      <th>barbecue sauce</th>\n      <th>black tea</th>\n      <th>blueberries</th>\n      <th>...</th>\n      <th>turkey</th>\n      <th>vegetables mix</th>\n      <th>water spray</th>\n      <th>white wine</th>\n      <th>whole weat flour</th>\n      <th>whole wheat pasta</th>\n      <th>whole wheat rice</th>\n      <th>yams</th>\n      <th>yogurt cake</th>\n      <th>zucchini</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 120 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "vector_data = pd.DataFrame(inds, columns=unique)\n",
    "vector_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      support                                 itemsets\n",
       "0    0.020397                                (almonds)\n",
       "1    0.033329                                (avocado)\n",
       "2    0.010799                         (barbecue sauce)\n",
       "3    0.014265                              (black tea)\n",
       "4    0.011465                             (body spray)\n",
       "..        ...                                      ...\n",
       "252  0.011065       (milk, ground beef, mineral water)\n",
       "253  0.017064  (ground beef, mineral water, spaghetti)\n",
       "254  0.015731         (milk, mineral water, spaghetti)\n",
       "255  0.010265    (mineral water, spaghetti, olive oil)\n",
       "256  0.011465     (pancakes, mineral water, spaghetti)\n",
       "\n",
       "[257 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>support</th>\n      <th>itemsets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.020397</td>\n      <td>(almonds)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.033329</td>\n      <td>(avocado)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.010799</td>\n      <td>(barbecue sauce)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014265</td>\n      <td>(black tea)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.011465</td>\n      <td>(body spray)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>0.011065</td>\n      <td>(milk, ground beef, mineral water)</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>0.017064</td>\n      <td>(ground beef, mineral water, spaghetti)</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>0.015731</td>\n      <td>(milk, mineral water, spaghetti)</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>0.010265</td>\n      <td>(mineral water, spaghetti, olive oil)</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>0.011465</td>\n      <td>(pancakes, mineral water, spaghetti)</td>\n    </tr>\n  </tbody>\n</table>\n<p>257 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "apriori(vector_data, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "source": [
    "This dataset doesn't appear to have many meanningful associations across the 7,5000 items bought. \n",
    "\n",
    "Sometimes this happens!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Apple   Corn   Dill   Eggs  Ice cream  Kidney Beans   Milk  Nutmeg  Onion  \\\n",
       "0  False  False  False   True      False          True   True    True   True   \n",
       "1  False  False   True   True      False          True  False    True   True   \n",
       "2   True  False  False   True      False          True   True   False  False   \n",
       "3  False   True  False  False      False          True   True   False  False   \n",
       "4  False   True  False   True       True          True  False   False   True   \n",
       "\n",
       "   Unicorn  Yogurt  \n",
       "0    False    True  \n",
       "1    False    True  \n",
       "2    False   False  \n",
       "3     True    True  \n",
       "4    False   False  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Apple</th>\n      <th>Corn</th>\n      <th>Dill</th>\n      <th>Eggs</th>\n      <th>Ice cream</th>\n      <th>Kidney Beans</th>\n      <th>Milk</th>\n      <th>Nutmeg</th>\n      <th>Onion</th>\n      <th>Unicorn</th>\n      <th>Yogurt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n",
    "\n",
    "te = TransactionEncoder()\n",
    "vdata = pd.DataFrame(te.fit(dataset).transform(dataset), columns=te.columns_)\n",
    "vdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    support                     itemsets\n",
       "0       0.8                       (Eggs)\n",
       "1       1.0               (Kidney Beans)\n",
       "2       0.6                       (Milk)\n",
       "3       0.6                      (Onion)\n",
       "4       0.6                     (Yogurt)\n",
       "5       0.8         (Kidney Beans, Eggs)\n",
       "6       0.6                (Eggs, Onion)\n",
       "7       0.6         (Kidney Beans, Milk)\n",
       "8       0.6        (Kidney Beans, Onion)\n",
       "9       0.6       (Kidney Beans, Yogurt)\n",
       "10      0.6  (Kidney Beans, Eggs, Onion)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>support</th>\n      <th>itemsets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.8</td>\n      <td>(Eggs)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>(Kidney Beans)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.6</td>\n      <td>(Milk)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.6</td>\n      <td>(Onion)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.6</td>\n      <td>(Yogurt)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.8</td>\n      <td>(Kidney Beans, Eggs)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.6</td>\n      <td>(Eggs, Onion)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Milk)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Onion)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Yogurt)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Eggs, Onion)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "frequent_items = apriori(vdata, min_support=0.6, use_colnames=True)\n",
    "\n",
    "frequent_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    support                     itemsets  length\n",
       "0       0.8                       (Eggs)       1\n",
       "1       1.0               (Kidney Beans)       1\n",
       "2       0.6                       (Milk)       1\n",
       "3       0.6                      (Onion)       1\n",
       "4       0.6                     (Yogurt)       1\n",
       "5       0.8         (Kidney Beans, Eggs)       2\n",
       "6       0.6                (Eggs, Onion)       2\n",
       "7       0.6         (Kidney Beans, Milk)       2\n",
       "8       0.6        (Kidney Beans, Onion)       2\n",
       "9       0.6       (Kidney Beans, Yogurt)       2\n",
       "10      0.6  (Kidney Beans, Eggs, Onion)       3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>support</th>\n      <th>itemsets</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.8</td>\n      <td>(Eggs)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>(Kidney Beans)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.6</td>\n      <td>(Milk)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.6</td>\n      <td>(Onion)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.6</td>\n      <td>(Yogurt)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.8</td>\n      <td>(Kidney Beans, Eggs)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.6</td>\n      <td>(Eggs, Onion)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Milk)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Onion)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Yogurt)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Eggs, Onion)</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "# add a column to the dataset measuring the lenght of the itemset tuples\n",
    "frequent_items['length'] = frequent_items['itemsets'].apply(len)\n",
    "frequent_items"
   ]
  },
  {
   "source": [
    "We can query our items to see where there are groupings greater than two, and with >= 0.8 support"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   support              itemsets  length\n",
       "5      0.8  (Kidney Beans, Eggs)       2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>support</th>\n      <th>itemsets</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0.8</td>\n      <td>(Kidney Beans, Eggs)</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "frequent_items[ (frequent_items['length'] == 2) &\n",
    "                   (frequent_items['support'] >= 0.8) ]"
   ]
  },
  {
   "source": [
    "We can also use pandas to query for certain item combinations.\n",
    "\n",
    "Here we search for whether `Kidney Beans` and `Yogurt` are ever bought together"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   support                itemsets  length\n",
       "9      0.6  (Kidney Beans, Yogurt)       2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>support</th>\n      <th>itemsets</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>0.6</td>\n      <td>(Kidney Beans, Yogurt)</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "frequent_items[frequent_items['itemsets'] == {'Kidney Beans', 'Yogurt'}]"
   ]
  },
  {
   "source": [
    "# Ensembles\n",
    "\n",
    "The goal of ensembling is to combine predcictions from several classifiers/regressors to improve generalizability when compared with a single classifier/regressor\n",
    "\n",
    "Two main groups of ensembling strategies exist\n",
    "\n",
    "    - Averaging methods, each algorithm independently trains and they average the predcictions\n",
    "    \n",
    "    - Boosting Methods, these algorithms are trained sequentially at each stage the next estimator is trying to reduce the combined bias."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     sepal_width  sepal_length  petal_length  petal_width\n0            3.5           5.1           1.4          0.2\n1            3.0           4.9           1.4          0.2\n2            3.2           4.7           1.3          0.2\n3            3.1           4.6           1.5          0.2\n4            3.6           5.0           1.4          0.2\n..           ...           ...           ...          ...\n145          3.0           6.7           5.2          2.3\n146          2.5           6.3           5.0          1.9\n147          3.0           6.5           5.2          2.0\n148          3.4           6.2           5.4          2.3\n149          3.0           5.9           5.1          1.8\n\n[150 rows x 4 columns]\n0         Iris-setosa\n1         Iris-setosa\n2         Iris-setosa\n3         Iris-setosa\n4         Iris-setosa\n            ...      \n145    Iris-virginica\n146    Iris-virginica\n147    Iris-virginica\n148    Iris-virginica\n149    Iris-virginica\nName: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "\n",
    "#In this example I am using one of the built in datasets\n",
    "#Some classification problems will give you pre defined train and test splits\n",
    "#in this case, as we don't have a train test split i make one using the functionality in sklearn\n",
    "\n",
    "\n",
    "\n",
    "iris = pd.read_csv(\"../../Datasets/Iris.csv\")\n",
    "\n",
    "X = iris[[\"sepal_width\",\"sepal_length\", \"petal_length\", \"petal_width\"]]\n",
    "y = iris[\"species\"]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "source": [
    "## Averaging Methods - Bagging\n",
    "\n",
    "Bagging is a form of averaging method, where the algorithm builds many instances of the classifier which are trained on random subsets of the original training data. These predictions are then combined to realise a single output. \n",
    "\n",
    "Bagging methods are often similar, but differ with respect to how the random samples are drawn.\n",
    "\n",
    "We can use the `BaggingClassifier` in SkLearn to wrap our base estimator - in this example the `DecisionTree`. \n",
    "\n",
    "When training bagging based classifiers, we can estimate the accuracy using the out-of-bag samples."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=0.4)\n",
    "bagging.fit(X_train, y_train)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 90,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=0.4,\n",
       "                  max_samples=0.5)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ]
  },
  {
   "source": [
    "## AdaBoost\n",
    "\n",
    "The main principle of AdaBoost is to to train a set of weak learners (models that are marginalyl better than random guessing) on repeteadly modified versions of the data.\n",
    "\n",
    "The predictions are then combined together using a weighted majority vote to produce the final prediction.\n",
    "\n",
    "The modified data is produced by taking the data and applying the weights to each of the training samples. These weights are initialised such that the first iteration of the algorithm trains on unmodified data. \n",
    "\n",
    "For each subsequent learner the weights are updated to and the algorithm is reapplied. \n",
    "\n",
    "Intuitively as the algorithm learns, cases that are difficult to predict have ever increasing influence over the algorith, and those that are easy to predict do not. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=10)"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# we can create an adaboost classifier by importing it from the ensemble module.\n",
    "# the default weak learner is DecisionTreeClassifier with a depth of 1\n",
    "# typically for ada boost you will have >= 50 estimators.\n",
    "ada_boost = AdaBoostClassifier(n_estimators=10)\n",
    "ada_boost.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## Gradient Tree Boosting\n",
    "\n",
    "Gradient tree boosting is a generlisation of boosting, and is a useful off-the-shelf tool to help on a variety of problems. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "g_boosting = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0)\n",
    "g_boosting.fit(X_train, y_train)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 92,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, n_estimators=10)"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ]
  },
  {
   "source": [
    "## Warm Start\n",
    "\n",
    "GradientBoosting classifiers allows you to use a warm start. This means you can partially train your models, and then add more estimators after the intial round of training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, n_estimators=20, warm_start=True)"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# add an additional 10 estimators. 10 -> 20\n",
    "# allow warm start\n",
    "g_boosting.set_params(n_estimators=20, warm_start=True)\n",
    "\n",
    "# use more data - using X_train again is illustrative\n",
    "g_boosting.fit(X_train, y_train)\n"
   ]
  },
  {
   "source": [
    "## Ensemble Voting (Classifiers)\n",
    "\n",
    "In majority voting the class label with the greatest number of votes is selected as the output\n",
    "\n",
    "for example:\n",
    "\n",
    "- classifier 1 -> class 1\n",
    "- classifier 2 -> class 1\n",
    " classifier 3 -> class 2\n",
    "\n",
    "votes = `[2, 1]`\n",
    "class 1 has the greatest number. \n",
    "\n",
    "\n",
    "In the event of ties, the class will be based on ascending order. \n",
    "\n",
    "- classifier 1 -> class 2\n",
    "- classifier 2 -> class 1\n",
    "\n",
    "votes = `[1,1]`\n",
    "\n",
    "class 1 will be selected.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The ensembles we have considered until now use a single base classifier or estimator, these are collectively referred to as homogenous ensembles.\n",
    "\n",
    "In this next section  we will consider heterogenous ensembles, where we use a mixture of different types of classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf1 = SVC()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = LogisticRegression()\n",
    "\n",
    "# pack the classifiers and string into a list of tuples.\n",
    "ensemble_clf = VotingClassifier(\n",
    "    [(\"SVM\", clf1), (\"Random Forest\", clf2), (\"kNN\", clf3), (\"Logistic Regression\", clf4)],\n",
    "    voting=\"hard\")\n",
    "\n",
    "# cross val and score each classifier.\n",
    "for name, clf  in [(\"SVM\", clf1), (\"Random Forest\", clf2), (\"kNN\", clf3), (\"Logistic Regression\", clf4), (\"Ensemble\", ensemble_clf)]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"{name} accuracy: {score}\")\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 94,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM accuracy: 0.9466666666666667\nRandom Forest accuracy: 0.9466666666666667\nkNN accuracy: 0.96\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-16633758f1d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# cross val and score each classifier.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m  \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVM\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forest\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"kNN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Logistic Regression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Ensemble\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{name} accuracy: {score}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1415\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m                       sample_weight=sample_weight)\n\u001b[1;32m-> 1417\u001b[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    762\u001b[0m             n_iter_i = _check_optimize_result(\n\u001b[0;32m    763\u001b[0m                 \u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m                 extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n\u001b[0m\u001b[0;32m    765\u001b[0m             \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\DeepRL\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_check_optimize_result\u001b[1;34m(solver, result, max_iter, extra_warning_msg)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;34m\"    https://scikit-learn.org/stable/modules/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;34m\"preprocessing.html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             ).format(solver, result.status, result.message.decode(\"latin1\"))\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_warning_msg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mwarning_msg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextra_warning_msg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ]
  }
 ]
}